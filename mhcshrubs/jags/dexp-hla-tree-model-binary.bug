## JAGS model -- baseline hla-tree-model
##
## In this version, the dependent variable is binary.
## We use a logit-bernoulli model for the likelihood

data {
    ## transformed data (NB: in JAGS, nodes can only be defined once in the model block)
    for ( i in 1:N ) {
        oneA1[i] <- 1
        oneA2[i] <- 1
        oneB1[i] <- 1
        oneB2[i] <- 1
        oneC1[i] <- 1
        oneC2[i] <- 1
    }

    ## uninformed Dirichlet distribution...
    for ( h in 1:HA ) { halvesA[h] <- 0.5 }
    for ( h in 1:HB ) { halvesB[h] <- 0.5 }
    for ( h in 1:HC ) { halvesC[h] <- 0.5 }

    ## precision for priors
    precision <- 1.0E-3
}

model {
    ## loop over the N patients
    for ( i in 1:N ) {
        log_like[i] <- log(dbern(Y[i], Q[i])) ## used for WAIC
        ## likelihood of observation Y, given predicted probability Q
        Y[i] ~ dbern(Q[i])
        ## the predicted probabiltiy is determined by the weights (beta) of the HLA alleles
        ## each participant has 3 times 2 alleles
        hlaEffect[i] <- betaA[hlaA1[i]] + betaA[hlaA2[i]] +
                        betaB[hlaB1[i]] + betaB[hlaB2[i]] +
                        betaC[hlaC1[i]] + betaC[hlaC2[i]]
        Q[i] <- ilogit(alpha + hlaEffect[i] - meanHlaEffect) ## TODO: covariates

        ## missing HLA data. The vectors cA1[,i], ..., cC2[,i] restrict the possible
        ## alleles for patient i. If the 4-digit allele is fully known, only one
        ## element of the vector is 1, otherwise, the vector contains multiple 1s
        hlaA1[i] ~ dcat(cA1[,i])
        hlaA2[i] ~ dcat(cA2[,i])
        hlaB1[i] ~ dcat(cB1[,i])
        hlaB2[i] ~ dcat(cB2[,i])
        hlaC1[i] ~ dcat(cC1[,i])
        hlaC2[i] ~ dcat(cC2[,i])

        ## likelihood of HLA distribution. Each participant contributes to the likelihood
        ## of the HLA distributions pA, pB and pC.
        oneA1[i] ~ dbern(pA[hlaA1[i]]) ## oneA1 is mock "data" and always 1
        oneA2[i] ~ dbern(pA[hlaA2[i]])
        oneB1[i] ~ dbern(pB[hlaB1[i]])
        oneB2[i] ~ dbern(pB[hlaB2[i]])
        oneC1[i] ~ dbern(pC[hlaC1[i]])
        oneC2[i] ~ dbern(pC[hlaC2[i]])
    }
    ## subtract "meanHlaEffect" from logit(Q[i])'s to de-correlate alpha with betas
    ## and get better precision for both.
    meanHlaEffect <- mean(hlaEffect)

    ## HLA frequency distribution
    pA ~ ddirch(halvesA)
    pB ~ ddirch(halvesB)
    pC ~ ddirch(halvesC)

    ## additional data to inform the frequency distributions.
    ## We use allele counts mA, mB and mC from Sub-Saharan Africa (SSA)
    ## to better estimate the Allele frequencies. NB: some alleles
    ## in the Durban cohort, have 0 frequency in the SSA sample. Therefore,
    ## we cannot use the SSA frequencies directly.
    mA ~ dmulti(pA, MA)
    mB ~ dmulti(pB, MB)
    mC ~ dmulti(pC, MC)

    ## prior of the HLA effects. The intercept of the virus load model
    alpha ~ dnorm(0.0, precision)

    ## prior on the weights of the nodes. The vector betaNodes contains
    ## the weights of the nodes of the HLA tree
    for ( k in 1:K ) {
        betaNodes[k] ~ ddexp(0.0, sqrt(2*tau_beta)) ## tau is precision (1/var)
    }
    ## precision of the node weight distribution
    tau_beta ~ dgamma(precision, precision)

    ## construct the leafs (betaA, betaB, betaC) using NodeMatrices.
    ## the elements of e.g. the vector NodeMatrixA1[,h] are 0 if
    ## the node is in the path from the root to the leaf of the HLA allele h,
    ## and 0 otherwise
    for ( h in 1:HA ) {
        betaA[h] <- inprod(NodeMatrixA[,h], lengthsEdgeToParent * betaNodes)
    }
    for ( h in 1:HB ) {
        betaB[h] <- inprod(NodeMatrixB[,h], lengthsEdgeToParent * betaNodes)
    }
    for ( h in 1:HC ) {
        betaC[h] <- inprod(NodeMatrixC[,h], lengthsEdgeToParent * betaNodes)
    }

    ## compute R^2 of the model. See the paper
    ## Gelman et al., R-squared for Bayesian regression models, 2017
    ## TODO: find the correct equivalent for binary observations: likelihood ratio R2?
    sdQ <- sd(Q) ## standard deviation of the "explained" part of the observation
    sdE <- sd(Y-Q) ## standard deviation of the error
    R2 <- sdQ * sdQ / (sdQ * sdQ + sdE + sdE) ## "alternative" R^2
}
