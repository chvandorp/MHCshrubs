## JAGS model incorporating "generalized homozygosity" and a double exponential weight prior

data {
    ## transformed data (NB: in JAGS, nodes can only be defined once in the model block)
    for ( i in 1:N ) {
        oneA1[i] <- 1
        oneA2[i] <- 1
        oneB1[i] <- 1
        oneB2[i] <- 1
        oneC1[i] <- 1
        oneC2[i] <- 1
    }

    ## uninformed dirichlet distribution...
    for ( h in 1:HA ) { halvesA[h] <- 0.5 }
    for ( h in 1:HB ) { halvesB[h] <- 0.5 }
    for ( h in 1:HC ) { halvesC[h] <- 0.5 }

    ## precision for priors
    precision <- 1.0E-3
}

model {
    ## loop over the N patients
    for ( i in 1:N ) {
        log_like[i] <- log(dnorm(V[i], W[i], tau_V)) ## used for WAIC
        ## likelihood of virus loads V, given a "predicted virus load W"
        V[i] ~ dnorm(W[i], tau_V)
        intervalCensorValue[i] ~ dinterval(V[i], VLbound[i])
        W[i] <- alpha + hlaEffect[i] - meanHlaEffect

        ## missing HLA data. The vectors cA1[,i], ..., cC2[,i] restrict the possible
        ## alleles for patient i. If the 4-digit allele is fully known, only one
        ## element of the vector is 1, otherwise, the vector contains multiple 1s
        hlaA1[i] ~ dcat(cA1[,i])
        hlaA2[i] ~ dcat(cA2[,i])
        hlaB1[i] ~ dcat(cB1[,i])
        hlaB2[i] ~ dcat(cB2[,i])
        hlaC1[i] ~ dcat(cC1[,i])
        hlaC2[i] ~ dcat(cC2[,i])

        ## likelihood of HLA distribution. Each patient contributes to the likelihood
        ## of the HLA distributions pA, pB and pC.
        oneA1[i] ~ dbern(pA[hlaA1[i]]) ## oneA1 is mock "data" and always 1
        oneA2[i] ~ dbern(pA[hlaA2[i]])
        oneB1[i] ~ dbern(pB[hlaB1[i]])
        oneB2[i] ~ dbern(pB[hlaB2[i]])
        oneC1[i] ~ dbern(pC[hlaC1[i]])
        oneC2[i] ~ dbern(pC[hlaC2[i]])

        ## find the nodes contributing for this HLA haplotype
        for ( k in 1:K ) {
            multiplicities[k, i] <- NodeMatrixA[k, hlaA1[i]] + NodeMatrixA[k, hlaA2[i]] +
                                    NodeMatrixB[k, hlaB1[i]] + NodeMatrixB[k, hlaB2[i]] +
                                    NodeMatrixC[k, hlaC1[i]] + NodeMatrixC[k, hlaC2[i]]
            adjustedMultiplicities[k, i] <- ifelse(multiplicities[k, i] > 0, 1, 0)
        }
        hlaEffect[i] <- inprod(adjustedMultiplicities[,i], lengthsEdgeToParent * betaNodes)
    }
    ## subtract "meanHlaEffect" from W[i]'s to de-correlate alpha with betas
    ## and get better precision for both.
    meanHlaEffect <- mean(hlaEffect)

    ## precision of V given the prediction W
    tau_V ~ dgamma(precision, precision)

    ## HLA frequency distribution
    pA ~ ddirch(halvesA)
    pB ~ ddirch(halvesB)
    pC ~ ddirch(halvesC)

    ## additional data to inform the frequency distributions.
    ## We use allele counts mA, mB and mC from Sub-Saharan Africa (SSA)
    ## to better estimate the Allele frequencies. NB: some alleles
    ## in the Durban cohort, have 0 frequency in the SSA sample. Therefore,
    ## we cannot use the SSA frequencies directly.
    mA ~ dmulti(pA, MA)
    mB ~ dmulti(pB, MB)
    mC ~ dmulti(pC, MC)

    ## prior of the HLA effects. The intercept of the virus load model
    alpha ~ dnorm(0.0, precision)

    ## prior on the weights of the nodes. The vector betaNodes contains
    ## the weights of the nodes of the HLA tree
    for ( k in 1:K ) {
        betaNodes[k] ~ ddexp(0.0, sqrt(2*tau_beta)) ## tau is precision (1/var)
    }
    ## precision of the node distribution
    tau_beta ~ dgamma(precision, precision)

    ## construct the leafs (betaA, betaB, betaC) using NodeMatrices.
    ## the elements of e.g. the vector NodeMatrixA1[,h] are 0 if
    ## the node is in the path from the root to the leaf of the HLA allele h,
    ## and 0 otherwise
    for ( h in 1:HA ) {
        betaA[h] <- inprod(NodeMatrixA[,h], lengthsEdgeToParent * betaNodes)
    }
    for ( h in 1:HB ) {
        betaB[h] <- inprod(NodeMatrixB[,h], lengthsEdgeToParent * betaNodes)
    }
    for ( h in 1:HC ) {
        betaC[h] <- inprod(NodeMatrixC[,h], lengthsEdgeToParent * betaNodes)
    }

    ## compute R^2 of the model. See the paper
    ## Gelman et al., R-squared for Bayesian regression models, 2017
    sdW <- sd(W) ## standard deviation of the data
    sdE <- sd(V-W) ## standard deviation of the error
    R2 <- sdW * sdW / (sdW * sdW + sdE + sdE) ## "alternative" R^2
}
